<!doctype html><html lang=en-us><head><meta http-equiv=x-clacks-overhead content="GNU Terry Pratchett"><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" href=https://AnthonyHongXiao.github.io/images/favicon.png><title>High-Dimensional Probability | Energy = Milk · Coffee^2</title><meta name=title content="High-Dimensional Probability"><meta name=description content="This file is for the notes and exercises for the book High-Dimensional Probability
Errata and update of the book: errata, update.
Exercises solns reference: soln.
0. Appetizer Key Takeaways convex combination $\sum^{m}{i=1}\lambda_i z_i$ where $\lambda_i\ge 0$ and $\sum^{m}{i=1}\lambda_i=1$.
convex hull of a set $T$, $\mathrm{conv}(T)={\text{convex combinations of }z_1,\cdots,z_m\in T\text{ for }m\in \mathbb{N}}$.
Theorem 0.0.1 (Caratheodory&rsquo;s Theorem): Every point in the convex hull of a set $T\subseteq \mathbb{R}^n$ can be expressed as a convex combination of at most $n+1$ points from $T$."><meta name=keywords content="probability,"><meta property="og:title" content="High-Dimensional Probability"><meta property="og:description" content="This file is for the notes and exercises for the book High-Dimensional Probability
Errata and update of the book: errata, update.
Exercises solns reference: soln.
0. Appetizer Key Takeaways convex combination $\sum^{m}{i=1}\lambda_i z_i$ where $\lambda_i\ge 0$ and $\sum^{m}{i=1}\lambda_i=1$.
convex hull of a set $T$, $\mathrm{conv}(T)={\text{convex combinations of }z_1,\cdots,z_m\in T\text{ for }m\in \mathbb{N}}$.
Theorem 0.0.1 (Caratheodory&rsquo;s Theorem): Every point in the convex hull of a set $T\subseteq \mathbb{R}^n$ can be expressed as a convex combination of at most $n+1$ points from $T$."><meta property="og:type" content="article"><meta property="og:url" content="https://AnthonyHongXiao.github.io/reading/high_dim_prob/"><meta property="og:image" content="https://AnthonyHongXiao.github.io/images/share.png"><meta property="article:section" content="reading"><meta property="article:published_time" content="2024-01-14T12:01:56+08:00"><meta property="article:modified_time" content="2024-01-14T12:01:56+08:00"><meta property="og:site_name" content="Hugo ʕ•ᴥ•ʔ Bear"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://AnthonyHongXiao.github.io/images/share.png"><meta name=twitter:title content="High-Dimensional Probability"><meta name=twitter:description content="This file is for the notes and exercises for the book High-Dimensional Probability
Errata and update of the book: errata, update.
Exercises solns reference: soln.
0. Appetizer Key Takeaways convex combination $\sum^{m}{i=1}\lambda_i z_i$ where $\lambda_i\ge 0$ and $\sum^{m}{i=1}\lambda_i=1$.
convex hull of a set $T$, $\mathrm{conv}(T)={\text{convex combinations of }z_1,\cdots,z_m\in T\text{ for }m\in \mathbb{N}}$.
Theorem 0.0.1 (Caratheodory&rsquo;s Theorem): Every point in the convex hull of a set $T\subseteq \mathbb{R}^n$ can be expressed as a convex combination of at most $n+1$ points from $T$."><meta itemprop=name content="High-Dimensional Probability"><meta itemprop=description content="This file is for the notes and exercises for the book High-Dimensional Probability
Errata and update of the book: errata, update.
Exercises solns reference: soln.
0. Appetizer Key Takeaways convex combination $\sum^{m}{i=1}\lambda_i z_i$ where $\lambda_i\ge 0$ and $\sum^{m}{i=1}\lambda_i=1$.
convex hull of a set $T$, $\mathrm{conv}(T)={\text{convex combinations of }z_1,\cdots,z_m\in T\text{ for }m\in \mathbb{N}}$.
Theorem 0.0.1 (Caratheodory&rsquo;s Theorem): Every point in the convex hull of a set $T\subseteq \mathbb{R}^n$ can be expressed as a convex combination of at most $n+1$ points from $T$."><meta itemprop=datePublished content="2024-01-14T12:01:56+08:00"><meta itemprop=dateModified content="2024-01-14T12:01:56+08:00"><meta itemprop=wordCount content="493"><meta itemprop=image content="https://AnthonyHongXiao.github.io/images/share.png"><meta itemprop=keywords content="probability,"><meta name=referrer content="no-referrer-when-downgrade"><style>body{font-family:Verdana,sans-serif;margin:auto;padding:20px;max-width:720px;text-align:left;background-color:#fff;word-wrap:break-word;overflow-wrap:break-word;line-height:1.5;color:#444}h1,h2,h3,h4,h5,h6,strong,b{color:#222}a{color:#3273dc}.title{text-decoration:none;border:0}.title span{font-weight:400}nav a{margin-right:10px}textarea{width:100%;font-size:16px}input{font-size:16px}content{line-height:1.6}table{width:100%}img{max-width:100%}code{padding:2px 5px;background-color:#f2f2f2}pre code{color:#222;display:block;padding:20px;white-space:pre-wrap;font-size:14px;overflow-x:auto}div.highlight pre{background-color:initial;color:initial}div.highlight code{background-color:unset;color:unset}blockquote{border-left:1px solid #999;color:#222;padding-left:20px;font-style:italic}footer{padding:25px;text-align:center}.helptext{color:#777;font-size:small}.errorlist{color:#eba613;font-size:small}ul.blog-posts{list-style-type:none;padding:unset}ul.blog-posts li{display:flex}ul.blog-posts li span{flex:0 0 130px}ul.blog-posts li a:visited{color:#8b6fcb}@media(prefers-color-scheme:dark){body{background-color:#333;color:#ddd}h1,h2,h3,h4,h5,h6,strong,b{color:#eee}a{color:#8cc2dd}code{background-color:#777}pre code{color:#ddd}blockquote{color:#ccc}textarea,input{background-color:#252525;color:#ddd}.helptext{color:#aaa}}.imagecenter{text-align:center}</style><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],throwOnError:!1})})</script></head><body><header><a href=/ class=title><h2>Energy = Milk · Coffee^2</h2></a><nav><a href=/>Home</a>
<a href=/course/>Courses</a>
<a href=/blog>Blog</a>
<a href=/reading>Reading</a></nav></header><main><content><p>This file is for the notes and exercises for the book <a href=/pdfs/HDP-book.pdf.>High-Dimensional Probability</a></p><p>Errata and update of the book: <a href=/pdfs/Vershynin-Errata-2020.pdf>errata</a>, <a href=Vershynin-Updates-2020.pdf>update</a>.</p><p>Exercises solns reference: <a href=https://zhuanlan.zhihu.com/p/338822722>soln</a>.</p><h1 id=0-appetizer>0. Appetizer</h1><h2 id=key-takeaways>Key Takeaways</h2><ol><li><p><strong>convex combination</strong> $\sum^{m}<em>{i=1}\lambda_i z_i$ where $\lambda_i\ge 0$ and $\sum^{m}</em>{i=1}\lambda_i=1$.</p></li><li><p><strong>convex hull of a set $T$</strong>, $\mathrm{conv}(T)={\text{convex combinations of }z_1,\cdots,z_m\in T\text{ for }m\in \mathbb{N}}$.</p></li><li><p><strong>Theorem 0.0.1 (Caratheodory&rsquo;s Theorem)</strong>: Every point in the convex hull of a set $T\subseteq \mathbb{R}^n$ can be expressed as a convex combination of at most $n+1$ points from $T$.</p></li><li><p><strong>Theorem 0.0.2 (Approximate form of Caratheodory&rsquo;s Theorem)</strong>: Consider a set $T\subseteq \mathbb{R}^n$ whose diameter is bounded by $1$. Then, for every point $x\in \mathrm{conv}(T)$ and every integer $k$, one can find points $x_1,\cdots,x_k\in T$ such that
$$
\left\Vert x-\frac{1}{k}\sum^{k}_{j=1}x_j\right\Vert^2_2\le \frac{1}{\sqrt{k}}
$$</p></li><li><p><strong>Corollary 0.0.4 (Covering polytopes by balls)</strong>: Let $P$ be a polytope in $\mathbb{R}^n$ with $N$ vertices and whose diameter is bounded by $1$. Then $P$ can be covered by at most $N^{\lceil{1}/{\varepsilon^2}\rceil}$ Euclidean balls of radii $\varepsilon>0$.</p></li></ol><h2 id=exercises>Exercises</h2><h3 id=exercise-003>Exercise 0.0.3</h3><p>Check the following variance identities, which we used in the proof of Theorem 0.0.2:</p><p>(a) Let $Z_1, \ldots, Z_k$ be independent mean-zero random vectors in $\mathbb{R}^n$. Show that
$$
\mathbb{E}\left\Vert\sum_{j=1}^k Z_j\right\Vert_2^2=\sum_{j=1}^k \mathbb{E}\left\Vert Z_j\right\Vert_2^2 .
$$</p><p>(b) Let $Z$ be a random vector in $\mathbb{R}^n$. Show that
$$
\mathbb{E}\Vert Z-\mathbb{E} Z\Vert_2^2=\mathbb{E}\Vert Z\Vert_2^2-\Vert\mathbb{E} Z\Vert_2^2
$$
<em>Soln</em>: routine (write each random vector as a tuple of random variables and remember to use independency and zero-mean).</p><h3 id=exercise-005>Exercise 0.0.5</h3><p>(The sum of binomial coefficients). Prove the inequalities
$$
\left(\frac{n}{m}\right)^m \leq\left(\begin{array}{c}
n \newline
m
\end{array}\right) \leq \sum_{k=0}^m\left(\begin{array}{l}
n \newline
k
\end{array}\right) \leq\left(\frac{e n}{m}\right)^m
$$
for all integers $m \in[1, n]$.
Hint: To prove the upper bound, multiply both sides by the quantity $(m / n)^m$, replace this quantity by $(m / n)^k$ in the left side, and use the Binomial Theorem.</p><p><em>Soln</em>: For the first inequality:
$$
\begin{aligned}
\mathrm{RHS}&=\frac{n!}{(n-m)!m!}=\frac{(n-m+1)\times\cdots\times n}{1\times \cdots\times m}\newline&=\left(\frac{n-m+1}{1}\right)\left(\frac{n-m+2}{2}\right)\cdots\left(\frac{n-1}{m-1}\right)\left(\frac{n}{m}\right)\newline
&\ge \left(\frac{n}{m}\right)\left(\frac{n}{m}\right)\cdots\left(\frac{n}{m}\right)\left(\frac{n}{m}\right)\newline
&=\mathrm{LHS}
\end{aligned}
$$
The second inequality is trivial as the right hand side contains $n\choose m$.</p><h4 id=lemma-lim-_n-rightarrow-inftyleft1fracxnrightnex>Lemma $\lim _{n \rightarrow \infty}\left(1+\frac{x}{n}\right)^n=e^x$</h4><p><em>proof</em>:
$$
\begin{aligned}
\lim_{n\to\infty}\left(1+\frac{x}{n}\right)^n&=\lim_{n\to\infty}e^{n \log \left(1+\frac{x}{n}\right)}\newline
&=e^{\lim_{n\to\infty}\frac{\log(1+x/n)}{1/n}}\newline
&=e^{\lim_{n\to\infty}\frac{(-x/n^2)(1/(1+x/n))}{-1/n^2}}\newline
&=e^{\lim_{n\to\infty}\frac{nx}{(x+n)}}\newline
&=e^{\lim_{n\to\infty}\frac{x}{1}}\newline
&=e^x
\end{aligned}
$$
The thrid inequality is then obtained using above lemma:
$$
\sum_{k=0}^m\left(\begin{array}{c}n \newline k\end{array}\right)\left(\frac{m}{n}\right)^m \leq \sum_{k=0}^n\left(\begin{array}{c}n \newline k\end{array}\right)\left(\frac{m}{n}\right)^k=\left(1+\frac{m}{n}\right)^n \leq e^m
$$</p><h3 id=exercise-006>Exercise 0.0.6</h3><p>(Improved covering). Check that in Corollary 0.0.4,
$$
\left(C+C \varepsilon^2 N\right)^{\left\lceil 1 / \varepsilon^2\right\rceil}
$$
suffice. Here $C$ is a suitable absolute constant. (Note that this bound is slightly stronger than $N^{\left\lceil 1 / \varepsilon^2\right\rceil}$ for small $\varepsilon$.)
Hint: The number of ways to choose $k$ elements from an $N$-element set with repetitions is $\left(\begin{array}{c}N+k-1 \newline k\end{array}\right)$. Simplify using Exercise 0.0.5.</p><p><em>soln</em>:</p><p>The number of ways to choose $k$ out of $N$ objects with repetition is
$$
\left(\begin{array}{c}
N+k-1 \newline
k
\end{array}\right) .
$$</p><p>Then, use inequalities in Exercise 0.0.5 to obtain
$$
\begin{aligned}
\left(\begin{array}{c}
N+k-1 \newline
k
\end{array}\right) & \leq\left[\frac{e(N+k-1)}{k}\right]^k=\left[\frac{e(k-1)}{k}+\frac{e N}{k}\right]^k \newline
& =\left[\frac{e(k-1)}{k}+\frac{e}{k \epsilon^2} \epsilon^2 N\right]^k \leq\left[C_\epsilon\left(1+\epsilon^2 N\right)\right]^{\left\lceil 1 / \epsilon^2\right\rceil}
\end{aligned}
$$
where $C_\epsilon=\frac{e}{\left[1 / \epsilon^2\right] \epsilon^2}$.</p><h1 id=1-preliminaries-on-random-variables>1. Preliminaries on Random Variables</h1><h2 id=key-takeaways-1>Key Takeaways</h2></content><p><a href=https://AnthonyHongXiao.github.io/blog/probability/>#probability</a></p></main><footer>Made with <a href=https://github.com/janraasch/hugo-bearblog/>Hugo ʕ•ᴥ•ʔ Bear</a></footer></body></html>